{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be7d5f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005252 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1485\n",
      "[LightGBM] [Info] Number of data points in the train set: 53856, number of used features: 154\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 0.080288\n",
      "[1]\tvalid_0's auc: 0.86488\tvalid_0's l2: 0.0687084\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's auc: 0.89255\tvalid_0's l2: 0.0666291\n",
      "[3]\tvalid_0's auc: 0.892983\tvalid_0's l2: 0.0646955\n",
      "[4]\tvalid_0's auc: 0.893603\tvalid_0's l2: 0.0629607\n",
      "[5]\tvalid_0's auc: 0.894677\tvalid_0's l2: 0.0616121\n",
      "[6]\tvalid_0's auc: 0.904556\tvalid_0's l2: 0.060149\n",
      "[7]\tvalid_0's auc: 0.904509\tvalid_0's l2: 0.0590332\n",
      "[8]\tvalid_0's auc: 0.906808\tvalid_0's l2: 0.0578026\n",
      "[9]\tvalid_0's auc: 0.908183\tvalid_0's l2: 0.056635\n",
      "[10]\tvalid_0's auc: 0.910775\tvalid_0's l2: 0.0555902\n",
      "[11]\tvalid_0's auc: 0.910126\tvalid_0's l2: 0.0546648\n",
      "[12]\tvalid_0's auc: 0.912847\tvalid_0's l2: 0.053816\n",
      "[13]\tvalid_0's auc: 0.914119\tvalid_0's l2: 0.0530656\n",
      "[14]\tvalid_0's auc: 0.915428\tvalid_0's l2: 0.0524834\n",
      "[15]\tvalid_0's auc: 0.915321\tvalid_0's l2: 0.0517844\n",
      "[16]\tvalid_0's auc: 0.916462\tvalid_0's l2: 0.0511496\n",
      "[17]\tvalid_0's auc: 0.917637\tvalid_0's l2: 0.0505315\n",
      "[18]\tvalid_0's auc: 0.918217\tvalid_0's l2: 0.0500639\n",
      "[19]\tvalid_0's auc: 0.918416\tvalid_0's l2: 0.049579\n",
      "[20]\tvalid_0's auc: 0.918986\tvalid_0's l2: 0.0491391\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's auc: 0.918986\tvalid_0's l2: 0.0491391\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#Load data\n",
    "data_training=pd.read_csv('census-income-training.csv',header=0)\n",
    "\n",
    "#Clean data\n",
    "#replace invalid or missing entries(delete individual row)\n",
    "data_training_clean=data_training.replace(regex=[r'\\?'],value=np.nan)\n",
    "data_training=data_training_clean.dropna(how='any')\n",
    "\n",
    "\n",
    "# Split the data into features and target label\n",
    "income_raw = data_training['income_morethan_50K']\n",
    "features_raw = data_training.drop(['income_morethan_50K','Id','GRINREG','MIGMTR1','MIGMTR3','MIGSAME','PARENT','PEFNTVTY','PEMNTVTY','PENATVTY'],axis=1)\n",
    "\n",
    "\n",
    "# Visualize skewed continuous features of original data\n",
    "#vs.distribution(data)\n",
    "\n",
    "# Log-transform the skewed features\n",
    "skewed = ['AHRSPAY','CAPGAIN', 'CAPLOSS','DIVVAL']\n",
    "features_log_transformed = pd.DataFrame(features_raw)\n",
    "features_log_transformed[skewed] = features_raw[skewed].apply(lambda x: np.log(x + 1))\n",
    "\n",
    "#Normalizing Numerical Features\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler() # default=(0, 1)\n",
    "numerical = ['AAGE', 'ADTOCC', 'AHRSPAY', 'CAPGAIN','CAPLOSS', 'DIVVAL','HHDREL','NOEMP']\n",
    "features_log_minmax_transform = pd.DataFrame(features_log_transformed)\n",
    "features_log_minmax_transform[numerical] = scaler.fit_transform(features_log_transformed[numerical])\n",
    "\n",
    "# Data Preprocessing: One-hot encode the 'features_log_minmax_transform' data using pandas.get_dummies()\n",
    "features_final = pd.get_dummies(features_log_minmax_transform)\n",
    "income_final= income_raw\n",
    "\n",
    "# Print the number of features after one-hot encoding\n",
    "#encoded = list(features_final.columns)\n",
    "#print ' total features after one-hot encoding.'\n",
    "#display (encoded)\n",
    "\n",
    "#Split the Data into Training and Test Sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(features_final,income_final,test_size = 0.2,random_state = 0)\n",
    "\n",
    "#Light GTB\n",
    "# from sklearn.datasets import make_hastie_10_2\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "import lightgbm as lgb\n",
    "lgb_train = lgb.Dataset(x_train, y_train) # 将数据保存到LightGBM二进制文件将使加载更快\n",
    "lgb_eval = lgb.Dataset(x_test, y_test, reference=lgb_train)  # 创建验证数据\n",
    "\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',  # 设置提升类型\n",
    "    'objective': 'regression', # 目标函数\n",
    "    'metric': {'l2', 'auc'},  # 评估函数\n",
    "    'num_leaves': 31,   # 叶子节点数\n",
    "    'learning_rate': 0.05,  # 学习速率\n",
    "    'feature_fraction': 0.9, # 建树的特征选择比例\n",
    "    'bagging_fraction': 0.8, # 建树的样本采样比例\n",
    "    'bagging_freq': 5,  # k 意味着每 k 次迭代执行bagging\n",
    "    'verbose': 1 # <0 显示致命的, =0 显示错误 (警告), >0 显示信息\n",
    "}\n",
    "\n",
    "gbm = lgb.train(params,lgb_train,num_boost_round=20,valid_sets=lgb_eval,early_stopping_rounds=5)\n",
    "\n",
    "\n",
    "gbm_y_predict=gbm.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2becc1ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
